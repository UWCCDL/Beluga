---
title: "Test FC Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2)
library(ggthemes)
library(ppcor)
library(reshape2)
library(gglasso)
```

# Test Functional Connectivity Pipeline

This is a test of the FC pipeline.

## Load and transform the data for every subject

First, let's load the Power 2011 region database. This will be used as an "atlas" throughout, to guide the development of the regions.

```{r}
power2011 <- read_csv("bin/power_2011.csv", 
                      col_types = cols(ROI=col_double(),
                                       X = col_double(),
                                       Y = col_double(),
                                       Z = col_double(),
                                       Network = col_double(),
                                       Color = col_character(),
                                       NetworkName = col_character())) %>%
  dplyr::select(ROI, X, Y, Z, Network, Color, NetworkName)
```


Then, let's create the functional connectivity matrix for every single subject in the dataset. This step can be skipped by setting the `CREATE_FC` variable to `F`. 

```{r}
CREATE_FC = F

if (CREATE_FC) {
  for (sub in dir()[grep("sub-*", dir())]) {
    roidata <- NULL
    for (roi in power2011$ROI) {
      network <- power2011 %>%
        filter(ROI == roi) %>%
        dplyr::select(Network) %>%
        as.numeric()
      
      network_name <- power2011 %>%
        filter(ROI == roi) %>%
        dplyr::select(NetworkName) %>%
        as.character()
      
      file_name <- paste("region_", 
                         sprintf("%03d", roi),  
                         "_network_", 
                         sprintf("%02d", max(0, network)), 
                         ".txt",
                         sep="")
      #mat <- t(read.table(paste(sub, "func", file_name, sep="/")))
      #pc1 <- prcomp(mat)  # PCA
      #pc1 <- pc1$x[,1]    # first PC
      mat <- colMeans(read.table(paste(sub, "func", file_name, sep="/")))
      pc1 <- mat
      table <- tibble(subject = sub,
                      scan = 1:209,
                      timeseries = pc1,
                      roi = roi,
                      network = network,
                      network_name = network_name)
      if (is.null(roidata)) {
        roidata <- table
      } else {
        roidata %<>% bind_rows(table)
      }
    }
    
    # Pivot long data format into wide data 
    wroidata <- roidata %>% pivot_wider(id_cols = scan, 
                                        names_from = roi, 
                                        values_from = timeseries)
    X  <- as.matrix(wroidata[,2:265])/1000 
    PR <- pcor(X)$estimate
    R  <- cor(X)
    
    # Generate matrices:
    
    # The partial correlation matrix
    long_pr <- melt(PR)
    #pdf(paste(sub, "fc_pcorr.pdf", sep="/"))
    ggplot(long_pr, aes(x=Var1, y=Var2)) +
      geom_raster(aes(fill=value)) +
      scale_fill_gradient2(limits=c(-1,1), 
                           low = "blue", 
                           high = "red", 
                           mid = "white") +
      theme_pander() +
      ggtitle(paste(sub, ": Functional Connectivity (Partial Correlations)", sep="")) +
      xlab("ROIs") +
      ylab("ROIs") 
    #dev.off()
    ggsave(paste(sub, "fc_pcorr.pdf", sep="/"))
    write.table(PR, col.names = T, 
                row.names = T, 
                file = paste(sub, "PR.txt", sep="/"))
    
    # The standard correlation matrix
    long_r <- melt(R)
    #pdf(paste(sub, "fc_corr.pdf", sep="/"))
    ggplot(long_r, aes(x=Var1, y=Var2)) +
      geom_raster(aes(fill=value)) +
      scale_fill_gradient2(limits=c(-1,1), low = "blue", high = "red", mid = "white") +
      theme_pander() +
      ggtitle(paste(sub, ": Functional Connectivity, Standard Correlations)", sep="")) +
      xlab("ROIs") +
      ylab("ROIs") 
    #dev.off()
    ggsave(paste(sub, "fc_corr.pdf", sep="/"))
    write.table(R, col.names = T, 
                row.names = T, 
                file = paste(sub, "R.txt", sep="/"))
  }
}
```

## Load the group-level data

We now need to load the group level data. In essence, to corresponds to create a matrix _X_ in which every individual is a row and every columns is a different ROI-to-ROI connection.

```{r}
NOFLY <- c()
cols <- outer(power2011$ROI, power2011$ROI, function(x, y) {paste(x, y, sep="-")})
cols %<>% as.vector

connection <- function(x, y) {
  paste(min(x, y), max(x, y), sep="-")
}

vconnection <- Vectorize(connection)

Mode <- function(x, na.rm=F) {
  if (na.rm) {
    x = x[!is.na(x)]
  }
  ux <- unique(x)
  return(ux[which.max(tabulate(match(x, ux)))])
}

reduced_power2011 <- power2011 %>% 
  dplyr::select(Network, NetworkName) %>%
  group_by(Network) %>%
  summarize(Network = mean(Network), NetworkName = Mode(NetworkName))

connection_name <- function(x, y) {
  first <- min(x, y)
  second <- max(x, y)
  paste(reduced_power2011 %>% filter(Network == first) %>% dplyr::select(NetworkName) ,
        reduced_power2011 %>% filter(Network == second) %>% dplyr::select(NetworkName),
        sep="-")
  
}

vconnection_name <- Vectorize(connection_name)


nets <- outer(power2011$Network, power2011$Network, vconnection)
nets %<>% as.vector
netnames <- outer(power2011$Network, power2011$Network, vconnection_name)
netnames %<>% as.vector

n <- length(grep("sub-*", dir()))
X <- matrix(data = rep(0, length(cols)*n), nrow =  n)

j <- 1

for (sub in dir()[grep("sub-*", dir())]) {
  M <- read.table(paste(sub, "PR.txt", sep="/"))
  v <- as_vector(M)  # v spreads M column-wise. M is symmetrical, so it should not matter, but better not risk it
  print(c(length(v), mean(v)))
  X[j,] <- v
  if (length(v[is.na(v)]) > 0) {
    print(paste("NA detected in sub", sub))
    NOFLY %<>% c(sub)  # Addes sub to NOFLY list
  }
  j <- j + 1
}

```

Now, we can restrict the analysis only to a limited set of networks (and their cross-network connections) by modifying the `NOI` (Networks of Interest) variable. The variable will be used to create a second list, `COI` (Connections of interest), which will contain the possible list of network-to-network connections 

```{r}
NOI <- c(
  # "Uncertain",
  # "Sensory/somatomotor Hand",
  # "Sensory/somatomotor Mouth",
  # "Cingulo-opercular Task Control",
  # "Auditory",
  "Default mode",
  "Memory retrieval?",
  # "Ventral attention",
  # "Visual",
  "Fronto-parietal Task Control"
  # "Salience",
  # "Subcortical",
  #"Cerebellar",
  #"Dorsal attention"
)

COI = outer(NOI, NOI, function(x, y) {paste(x, y, sep="-")})

```


Now, we need to remove some columns from the hyper-large X matrix, and define proper groupings for Lasso.

```{r}
# Here we simplify create a tibble which the X columns, and create a censor column to decide which ones to keep
# If ROI1 = i and ROI2 = j, we keep column <i,j> IFF i < j.  This should keep the lower triangle.
censor <- outer(power2011$ROI, power2011$ROI, function(x, y) {x < y}) %>% as.vector()

order <- tibble(index = 1:length(nets), 
                network = nets, 
                network_names = netnames,
                connection = cols, 
                censor=censor)
order %<>% arrange(network)


I <- order %>%
  filter(censor == TRUE) %>%
  filter(network_names %in% COI) %>%
  dplyr::select(index) 

G <- order %>%
  filter(censor == TRUE) %>%
  filter(network_names %in% COI) %>%
  dplyr::select(network) 
```  


```{r}
# G is the real grouping factor for Lasso!

# The real X:
X <- X[,as_vector(I)]
```

## Load the dependent variable $Y$

Now we need to load the dependent variable. In this case, it is the rate of forgetting $alpha$, which is stored as part of the participants' meta-data in `participats.tsv`. 

Note that we could not measure $alpha$ for all participants, so we have to keep track of which rows in the $X$ regressor matrix we want to exclude from our Lasso analysis.

```{r}
dvs <- read.table("participants.tsv", sep="\t", header=T)
keep <- !is.na(dvs$SymmetrySpan)  & !dvs$Subject %in% NOFLY
Y <- dvs$SymmetrySpan[keep]
X <- X[keep,]
```

# Lasso part

With all the pieces in place, we can now do the Lasso:

```{r}
fit <- gglasso(y = Y,
               x = X,
               group = as.numeric(factor(G$network)),
               loss = 'ls',
               #lambda = exp(seq(-13, -6.5, 0.25)))
               nlambda = 50,
               lambda.factor = 0.05)

fit.cv <- cv.gglasso(y = Y,
                     x = X,
                     group = as.numeric(factor(G$network)),
                     pred.loss="L1",
                     nfolds=5,
                     #lambda=exp(seq(-13, -6.5, 0.25)))
                     nlambda = 50,
                     lambda.factor = 0.05)
plot(fit.cv)
plot(fit, group=T, col=rainbow(100))
```

## Predicted vs. Observed

```{r}
prediction <- predict(object=fit, 
                      newx=X, 
                      s=fit.cv$lambda.min, 
                      type="link")

observed <-tibble(Subject = dvs$Subject[keep], 
                  Alpha=Y, 
                  Condition="Observed")

predicted <- tibble(Subject = dvs$Subject[keep], 
                    Alpha = prediction, 
                    Condition="Predicted")

comparison <- as_tibble(rbind(observed, predicted))

ggplot(comparison, aes(x=reorder(Subject, Alpha), y=Alpha), col=Condition) +
  geom_point(aes(col=Condition)) +
  geom_line(alpha=0.5, lty=0.2) +
  xlab("Subject")+
  annotate("text", x=20, y=0.20,
           label=paste("r =", round(cor(Y, prediction), 5))) +
  theme_pander() +
  ylab("Rate of Forgetting (Alpha)") +
  theme(axis.text.x = element_text(angle=90, hjust=1, size = 8))

```