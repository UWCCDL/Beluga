"Visual",
"Fronto-parietal Task Control",
"Salience",
"Subcortical",
"Cerebellar",
"Dorsal attention"
)
COI <- outer(NOI,
NOI,
function(x, y) {paste(x, y, sep="-")}) %>% as.vector()
# Here we simplify create a tibble which the X columns, and create a censor column to decide which ones to keep
# If ROI1 = i and ROI2 = j, we keep column <i,j> IFF i < j.  This should keep the lower triangle.
censor <- outer(power2011$ROI,
power2011$ROI,
function(x, y) {x < y}) %>% as.vector()
censor2 <- colMeans(C) %>% abs() > 0.1
order <- tibble(index = 1:length(nets),
network = nets,
network_names = netnames,
connection = cols,
censor=censor,
censor2 = censor2)
order %<>% arrange(network)
I <- order %>%
filter(censor == TRUE) %>%
filter(censor2 == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(index)
G <- order %>%
filter(censor == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(network)
# G is the real grouping factor for Lasso!
# The real X:
X <- C[,as_vector(I)]
dvs1<- read_tsv("../rsfmri/participants.tsv")
dvs2 <- read_csv("PythonOutcomes.csv") %>%
filter(Subject != "NO RS")
dvs <- full_join(dvs1, dvs2)
keep <- !is.na(dvs$LearningRate)  & !dvs$Subject %in% NOFLY
Y <- dvs$LearningRate[keep]
X <- X[keep,]
dim(X)
corX <- cor(X)
distCor <- as_vector(corX[lower.tri(corX, diag = F)])
distTibble <- as_tibble(data.frame(R=distCor))
ggplot(distTibble, aes(x=R)) +
geom_histogram(col="white") +
theme_pander() +
ylab("Number of Correlations") +
xlab("Correlation Value") +
ggtitle("Distribution of Correlation Values Between Regressors")
dependent <- as_tibble(data.frame(alpha=Y))
#d3 <- pal_d3()
#kol = d3(7)
ggplot(dependent, aes(x=alpha, fill=cut(alpha, 7))) +
geom_histogram(bins=8, col="white", alpha=0.5) +
scale_fill_viridis(option = "plasma", discrete=T) +
geom_vline(xintercept = mean(dependent$alpha)) +
xlab(expression(paste("Learning Rate (", beta, ")")))+
ylab("Number of Participants") +
ggtitle("Distribution of Learning Rates") +
theme_pander() +
theme(legend.position = "none")
# fit <- ncvreg
fit <- glmnet(y = Y,
x = X,
alpha=1,
#lambda.min = 0.5,
#lam= 0.04978707,#log(length(Y)),
standardize = T
)
#fit.cv <- cv.ncvreg(y = Y,
fit.cv <- cv.glmnet(y = Y,
x = X,
alpha=1,
# lam=exp(seq(-3, -10, -0.1)),
#penalty="SCAD",
standardize=T,
nfolds=length(Y)
)
plot(fit.cv)
plot(fit, sub="Beta Values for Connectivity")
L1norm <- sum(abs(fit$beta[,which(fit$lambda==fit.cv$lambda.min)]))
abline(v=L1norm, lwd=2, lty=2)
dvs1<- read_tsv("../rsfmri/participants.tsv")
dvs2 <- read_csv("PythonOutcomes.csv") %>%
filter(Subject != "NO RS")
dvs <- full_join(dvs1, dvs2)
keep <- !is.na(dvs$ProgrammingAccuracy)  & !dvs$Subject %in% NOFLY
Y <- dvs$LearningRate[keep]
X <- X[keep,]
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2)
library(ggthemes)
library(ppcor)
library(reshape2)
#library(gglasso)
library(glmnet)
library(ggsci)
library(viridis)
library(ggExtra)
library(kableExtra)
library(xtable)
library(ggrepel)
library(scales)
library(car)
library(patchwork)      # Multi-plot alignment
#library(data.table)
# Simulate ACT-R
decay <- function(time, t0=0, rate=.5) {
if (time <= t0) {
NA
} else {
(time - t0)**(-rate)
}
}
vdecay <- Vectorize(decay)
time <- seq(1, 100, 0.1)
t1 = vdecay(time, t0=1)
t2 = vdecay(time, t0=20)
t3 = vdecay(time, t0=55)
t4 = vdecay(time, t0=65)
traces_df <-tibble(Time=time,
trace1 = vdecay(time, t0=1),
trace2 = vdecay(time, t0=20),
trace3 = vdecay(time, t0=55),
trace4 = vdecay(time, t0=65))
ltraces_df <- traces_df %>%
pivot_longer(cols = c("trace1", "trace2", "trace3", "trace4"),
names_to = "Trace", values_to="Activation")
ltraces_df$Trace <- fct_recode(ltraces_df$Trace,
"Trace 1" = "trace1",
"Trace 2" = "trace2",
"Trace 3" = "trace3",
"Trace 4" = "trace4")
ltraces_df <- ltraces_df %>%
add_column(Source="Individual Traces")
t1[is.na(t1)] <-0
t2[is.na(t2)] <-0
t3[is.na(t3)] <-0
t4[is.na(t4)] <-0
memory <- log(t1+t2+t3+t4)
memory_df <- tibble(Time=time,
Activation = memory,
Trace = "Memory",
Source="Memory")
p1 <- ggplot(ltraces_df,
aes(x=Time, y=Activation, col=Trace)) +
geom_line(size=1,
alpha=1) +
ylab("Retrieval Odds") +
ggtitle("Individual Traces") +
scale_color_viridis("", option="plasma", discrete=T, end = .8, direction=1) +
#scale_color_d3() +
theme_pander()
p2 <- ggplot(memory_df,
aes(x=Time, y=Activation)) +
geom_line(size=1,
alpha=0.5,
col="blue") +
ylab("Memory Activation") +
ggtitle("Memory") +
theme_pander()
p1 / p2
power2011 <- read_csv("../rsfmri/bin/power_2011.csv",
col_types = cols(ROI=col_double(),
X = col_double(),
Y = col_double(),
Z = col_double(),
Network = col_double(),
Color = col_character(),
NetworkName = col_character())) %>%
dplyr::select(ROI, X, Y, Z, Network, Color, NetworkName)
CREATE_FC = F
if (CREATE_FC) {
for (sub in dir()[grep("sub-*", dir())]) {
roidata <- NULL
for (roi in power2011$ROI) {
network <- power2011 %>%
filter(ROI == roi) %>%
dplyr::select(Network) %>%
as.numeric()
network_name <- power2011 %>%
filter(ROI == roi) %>%
dplyr::select(NetworkName) %>%
as.character()
file_name <- paste("region_",
sprintf("%03d", roi),
"_network_",
sprintf("%02d", max(0, network)),
".txt",
sep="")
#mat <- t(read.table(paste(sub, "func", file_name, sep="/")))
#pc1 <- prcomp(mat)  # PCA
#pc1 <- pc1$x[,1]    # first PC
mat <- colMeans(read.table(paste(sub, "func", file_name, sep="/")))
pc1 <- mat
table <- tibble(subject = sub,
scan = 1:209,
timeseries = pc1,
roi = roi,
network = network,
network_name = network_name)
if (is.null(roidata)) {
roidata <- table
} else {
roidata %<>% bind_rows(table)
}
}
# Pivot long data format into wide data
wroidata <- roidata %>% pivot_wider(id_cols = scan,
names_from = roi,
values_from = timeseries)
X  <- as.matrix(wroidata[,2:265])/1000
PR <- pcor(X)$estimate
R  <- cor(X)
# Generate matrices:
# The partial correlation matrix
long_pr <- melt(PR)
#pdf(paste(sub, "fc_pcorr.pdf", sep="/"))
ggplot(long_pr, aes(x=Var1, y=Var2)) +
geom_raster(aes(fill=value)) +
scale_fill_gradient2(limits=c(-1,1),
low = "blue",
high = "red",
mid = "white") +
theme_pander() +
ggtitle(paste(sub, ": Functional Connectivity (Partial Correlations)", sep="")) +
xlab("ROIs") +
ylab("ROIs")
#dev.off()
ggsave(paste(sub, "fc_pcorr.pdf", sep="/"))
write.table(PR, col.names = T,
row.names = T,
file = paste(sub, "PR.txt", sep="/"))
# The standard correlation matrix
long_r <- melt(R)
#pdf(paste(sub, "fc_corr.pdf", sep="/"))
ggplot(long_r, aes(x=Var1, y=Var2)) +
geom_raster(aes(fill=value)) +
scale_fill_gradient2(limits=c(-1,1), low = "blue", high = "red", mid = "white") +
theme_pander() +
ggtitle(paste(sub, ": Functional Connectivity, Standard Correlations)", sep="")) +
xlab("ROIs") +
ylab("ROIs")
#dev.off()
ggsave(paste(sub, "fc_corr.pdf", sep="/"))
write.table(R, col.names = T,
row.names = T,
file = paste(sub, "R.txt", sep="/"))
}
}
NOFLY <- c()
cols <- outer(power2011$ROI, power2011$ROI, function(x, y) {paste(x, y, sep="-")})
cols %<>% as.vector
connection <- function(x, y) {
paste(min(x, y), max(x, y), sep="-")
}
vconnection <- Vectorize(connection)
Mode <- function(x, na.rm=F) {
if (na.rm) {
x = x[!is.na(x)]
}
ux <- unique(x)
return(ux[which.max(tabulate(match(x, ux)))])
}
reduced_power2011 <- power2011 %>%
dplyr::select(Network, NetworkName) %>%
group_by(Network) %>%
summarize(Network = mean(Network), NetworkName = Mode(NetworkName))
connection_name <- function(x, y) {
first <- min(x, y)
second <- max(x, y)
paste(reduced_power2011 %>% filter(Network == first) %>% dplyr::select(NetworkName) ,
reduced_power2011 %>% filter(Network == second) %>% dplyr::select(NetworkName),
sep="-")
}
vconnection_name <- Vectorize(connection_name)
connection_name2 <- function(x, y) {
first <- min(x, y)
second <- max(x, y)
paste(reduced_power2011$NetworkName[reduced_power2011$Network == first],
reduced_power2011$NetworkName[reduced_power2011$Network == second],
sep="-")
}
vconnection_name2 <- Vectorize(connection_name2)
nets <- outer(power2011$Network, power2011$Network, vconnection)
nets %<>% as.vector
netnames <- outer(power2011$Network, power2011$Network, vconnection_name2)
netnames %<>% as.vector
n <- length(grep("sub-*", dir("../rsfmri/")))
C <- matrix(data = rep(0, length(cols)*n), nrow =  n)
j <- 1
R <- NULL
PR <- NULL
for (sub in dir("../rsfmri/")[grep("sub-*", dir("../rsfmri/"))]) {
M <- read.table(paste("../rsfmri", sub, "PR.txt", sep="/"))
v <- as_vector(M)  # v spreads M column-wise. M is symmetrical, so it should not matter, but better not risk it
#print(c(length(v), mean(v)))
C[j,] <- v
if (length(v[is.na(v)]) > 0) {
print(paste("NA detected in sub", sub))
NOFLY %<>% c(sub)  # Addes sub to NOFLY list
}
j <- j + 1
}
# Create python-compatible data
#
# for (sub in dir()[grep("sub-*", dir())]) {
#   R1 <- read.table(paste(sub, "R.txt", sep="/"))
#   R2 <- read.table(paste(sub, "PR.txt", sep="/"))
#   write.table(R1, paste(sub, "R_py.txt", sep="/"), sep = " ", row.names = F, col.names=F)
#   write.table(R2, paste(sub, "PR_py.txt", sep="/"), sep = " ", row.names = F, col.names=F)
# }
NOI <- c(
"Uncertain",
"Sensory/somatomotor Hand",
"Sensory/somatomotor Mouth",
"Cingulo-opercular Task Control",
"Auditory",
"Default mode",
"Memory retrieval?",
"Ventral attention",
"Visual",
"Fronto-parietal Task Control",
"Salience",
"Subcortical",
"Cerebellar",
"Dorsal attention"
)
COI <- outer(NOI,
NOI,
function(x, y) {paste(x, y, sep="-")}) %>% as.vector()
# Here we simplify create a tibble which the X columns, and create a censor column to decide which ones to keep
# If ROI1 = i and ROI2 = j, we keep column <i,j> IFF i < j.  This should keep the lower triangle.
censor <- outer(power2011$ROI,
power2011$ROI,
function(x, y) {x < y}) %>% as.vector()
censor2 <- colMeans(C) %>% abs() > 0.1
order <- tibble(index = 1:length(nets),
network = nets,
network_names = netnames,
connection = cols,
censor=censor,
censor2 = censor2)
order %<>% arrange(network)
I <- order %>%
filter(censor == TRUE) %>%
filter(censor2 == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(index)
G <- order %>%
filter(censor == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(network)
# G is the real grouping factor for Lasso!
# The real X:
X <- C[,as_vector(I)]
dvs1<- read_tsv("../rsfmri/participants.tsv")
dvs2 <- read_csv("PythonOutcomes.csv") %>%
filter(Subject != "NO RS")
dvs <- full_join(dvs1, dvs2)
keep <- !is.na(dvs$ProgrammingAccuracy)  & !dvs$Subject %in% NOFLY
Y <- dvs$LearningRate[keep]
X <- X[keep,]
# fit <- ncvreg
fit <- glmnet(y = Y,
x = X,
alpha=1,
#lambda.min = 0.5,
#lam= 0.04978707,#log(length(Y)),
standardize = T
)
#fit.cv <- cv.ncvreg(y = Y,
fit.cv <- cv.glmnet(y = Y,
x = X,
alpha=1,
# lam=exp(seq(-3, -10, -0.1)),
#penalty="SCAD",
standardize=T,
nfolds=length(Y)
)
plot(fit.cv)
plot(fit, sub="Beta Values for Connectivity")
L1norm <- sum(abs(fit$beta[,which(fit$lambda==fit.cv$lambda.min)]))
abline(v=L1norm, lwd=2, lty=2)
# Here we simplify create a tibble which the X columns, and create a censor column to decide which ones to keep
# If ROI1 = i and ROI2 = j, we keep column <i,j> IFF i < j.  This should keep the lower triangle.
censor <- outer(power2011$ROI,
power2011$ROI,
function(x, y) {x < y}) %>% as.vector()
censor2 <- colMeans(C) %>% abs() > 0.2
order <- tibble(index = 1:length(nets),
network = nets,
network_names = netnames,
connection = cols,
censor=censor,
censor2 = censor2)
order %<>% arrange(network)
I <- order %>%
filter(censor == TRUE) %>%
filter(censor2 == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(index)
G <- order %>%
filter(censor == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(network)
# G is the real grouping factor for Lasso!
# The real X:
X <- C[,as_vector(I)]
dvs1<- read_tsv("../rsfmri/participants.tsv")
dvs2 <- read_csv("PythonOutcomes.csv") %>%
filter(Subject != "NO RS")
dvs <- full_join(dvs1, dvs2)
keep <- !is.na(dvs$ProgrammingAccuracy)  & !dvs$Subject %in% NOFLY
Y <- dvs$LearningRate[keep]
X <- X[keep,]
corX <- cor(X)
distCor <- as_vector(corX[lower.tri(corX, diag = F)])
distTibble <- as_tibble(data.frame(R=distCor))
ggplot(distTibble, aes(x=R)) +
geom_histogram(col="white") +
theme_pander() +
ylab("Number of Correlations") +
xlab("Correlation Value") +
ggtitle("Distribution of Correlation Values Between Regressors")
# fit <- ncvreg
fit <- glmnet(y = Y,
x = X,
alpha=1,
#lambda.min = 0.5,
#lam= 0.04978707,#log(length(Y)),
standardize = T
)
#fit.cv <- cv.ncvreg(y = Y,
fit.cv <- cv.glmnet(y = Y,
x = X,
alpha=1,
# lam=exp(seq(-3, -10, -0.1)),
#penalty="SCAD",
standardize=T,
nfolds=length(Y)
)
plot(fit.cv)
plot(fit, sub="Beta Values for Connectivity")
L1norm <- sum(abs(fit$beta[,which(fit$lambda==fit.cv$lambda.min)]))
abline(v=L1norm, lwd=2, lty=2)
dvs1<- read_tsv("../rsfmri/participants.tsv")
dvs2 <- read_csv("PythonOutcomes.csv") %>%
filter(Subject != "NO RS")
dvs <- full_join(dvs1, dvs2)
keep <- !is.na(dvs$LearningRate)  & !dvs$Subject %in% NOFLY
Y <- dvs$LearningRate[keep]
X <- X[keep,]
# Here we simplify create a tibble which the X columns, and create a censor column to decide which ones to keep
# If ROI1 = i and ROI2 = j, we keep column <i,j> IFF i < j.  This should keep the lower triangle.
censor <- outer(power2011$ROI,
power2011$ROI,
function(x, y) {x < y}) %>% as.vector()
censor2 <- colMeans(C) %>% abs() > 0.2
order <- tibble(index = 1:length(nets),
network = nets,
network_names = netnames,
connection = cols,
censor=censor,
censor2 = censor2)
order %<>% arrange(network)
I <- order %>%
filter(censor == TRUE) %>%
filter(censor2 == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(index)
G <- order %>%
filter(censor == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(network)
# G is the real grouping factor for Lasso!
# The real X:
X <- C[,as_vector(I)]
dvs1<- read_tsv("../rsfmri/participants.tsv")
dvs2 <- read_csv("PythonOutcomes.csv") %>%
filter(Subject != "NO RS")
dvs <- full_join(dvs1, dvs2)
keep <- !is.na(dvs$LearningRate)  & !dvs$Subject %in% NOFLY
Y <- dvs$LearningRate[keep]
X <- X[keep,]
# fit <- ncvreg
fit <- glmnet(y = Y,
x = X,
alpha=1,
#lambda.min = 0.5,
#lam= 0.04978707,#log(length(Y)),
standardize = T
)
#fit.cv <- cv.ncvreg(y = Y,
fit.cv <- cv.glmnet(y = Y,
x = X,
alpha=1,
# lam=exp(seq(-3, -10, -0.1)),
#penalty="SCAD",
standardize=T,
nfolds=length(Y)
)
plot(fit.cv)
plot(fit, sub="Beta Values for Connectivity")
L1norm <- sum(abs(fit$beta[,which(fit$lambda==fit.cv$lambda.min)]))
abline(v=L1norm, lwd=2, lty=2)
